Big O Notation
Big O is worst case senario   f = O(g)  f <= g
Omega is best case senario    f = omega(g) g = O(f)
Theta is worst and best case are equal  f = theta(g) f = O(g) and f = omega(g)

f1(n) = n^2
f2(n) = 2n+20
f3(n) = n + 1

1 < logn < sqrt(n) < n < nlogn < n^2 < n^3 < ... < 2^n < n! < n^n

Iterative Mergesort

Divide and conquer strategy
Solves a problem by:
-Breaking it into subproblems
-Recursivly solving
-Appropriately combining
Correctness can be proven by mathematical induction
computational cost can be found by solving recurrence relations
implemented as recursive procedures

Binary Search

Quicksort
Choose a pivot
While i<j
	increment j until you find an element greater than pivot
	decrement j until you find an element smaller than pivot
	if i<j
	then swap(A[i],A[j])
swap(A[low],A[j])
return j //changing the pivot

Recurrence Relations
-Tackle a problem of size n
-By recursively solving a subproblems of size n/b
-and then combine these answers in O(n^d) time
-For some a,b,d > 0

Running time: T(n) = aT (ceiling(n/b) ) + O(n^d)

Mergesort
Running time:
a=2, b=2, O(n^d) = O(n)
T(n) = 2T(n/2) + O(n)

a = how many subproblems
n/b = size of subproblem
d = time to combine

Master Theorem
If T(n) = aT(ceiling(n/b)) + O(n^d) for some constants a > 0, b>1, d>=0, then 
T(n) = O(n^d)             if d > logb(a)
T(n) = O(n^dlogn)         if d = logb(a)
T(n) = O(n^lobb a)        if d < logb(a)

binary search
a = 1
b = 2
d = 0   O(n^0)





